# ERQ-META-BEGIN
# {"doc_type":"workflow","spec_version":"2.2","source_baseline_hash":"d0ae1e584b81c6470bec874c69019e0b4d20fa93d3b14c7ec013d1c2246863fa","provenance":{"build_id":"7fc1d1f7-a863-4742-9017-04b03c3e0fd0","built_at":"2025-09-12T02:41:58Z","builder":"EREP v2.2","tools":{"python":"3.11.8"}},"governance_links":{"acceptance_gates":"00_repo/.cbr/acceptance_gates.yaml","registry":"00_repo/.cbr/registry.json","audit_log":"00_repo/.cbr/audit_log.json"},"canonicalization":{"encoding":"utf-8","newline":"LF","sort_keys":true},"integrity":{"algo":"sha256","canonical_scope":"payload","value":"db090fb62bf0018a53406ede6ec3ace53e5e0511e044b625bba70ec657568709"}}
# ERQ-META-END
name: InferencePipeline
version: 1.0
determinism:
  tz: UTC
  seed: 1729
inputs:
  feature_store: 03_Data/feature_store/latest/
  schema: 03_Data/machine/schema_registry.json#inference_features_v1
model:
  id: model_001
  path: 10_AI_Algo/machine/models/model_001/
  hash: "sha256:pending"
runtime:
  batch_size: 1024
  device: cpu
  num_workers: 2
  latency_slo_ms: 100
steps:
  - id: load_features
    type: read_parquet
  - id: preprocess
    type: normalize
    options:
      standardize: true
      handle_missing: zero
  - id: run_model
    type: inference
  - id: postprocess
    type: threshold
    options:
      decision_threshold: 0.6
logging:
  level: INFO
  write: 13_OpsLog/machine/ops_activity.log
rollback:
  on_failure: disable_signal "trade_execute"
  notify: [ "@ops", "@master-control" ]
