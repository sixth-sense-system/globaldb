# ERQ-META-BEGIN
# {"canonicalization": {"encoding": "utf-8", "newline": "LF", "sort_keys": true}, "doc_type": "machine_spec", "governance_links": {"acceptance_gates": "ENERQIS_GlobalDB_TREEBUILD/00_repo/.cbr/acceptance_gates.yaml", "audit_log": "ENERQIS_GlobalDB_TREEBUILD/00_repo/.cbr/audit_log.json", "registry": "ENERQIS_GlobalDB_TREEBUILD/00_repo/.cbr/registry.json"}, "integrity": {"algo": "sha256", "canonical_scope": "payload", "value": "73ca3b0211c8aab93097d262b05b1324a879e85096d649d471a738c216635295"}, "provenance": {"build_id": "01b444c7-1544-41af-83d9-05f5df89df6d", "builder": "EREP v2.2", "built_at": "2025-09-12T02:29:07Z", "tools": {"hashlib": "sha256", "platform": "Linux-4.4.0-x86_64-with-glibc2.36", "python": "3.11.8"}}, "source_baseline_hash": "sha256:a16aa6c5ed17ee977a3aec9f4a0c058be2d9121a693d4247fc8a1853dff10191", "spec_version": "2.0"}
# ERQ-META-END
# 03_Data â€” Glossary

- **ETL:** Extract, Transform, Load
- **Feature Store:** Centralized repository for normalized datasets.
- **Deterministic Hash:** Cryptographic hash that uniquely identifies a dataset version.
- **Normalization:** Process of converting data into a standardized format.
- **Parquet/Arrow:** Columnar storage formats optimized for analytics.
- **Pipeline:** Series of automated steps for data ingestion, normalization, or transformation.
- **Ops/Log:** Operational logging module for traceability and auditing.
